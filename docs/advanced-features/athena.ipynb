{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe895e07-0f59-4803-9600-fe7fa5b30d1f",
   "metadata": {},
   "source": [
    "# Querying package metadata with Athena\n",
    "Quilt stores package data and metadata in S3. Metadata lives in a per-package manifest file in each bucket's `.quilt/` directory.\n",
    "\n",
    "You can therefore query package metadata wth SQL engines like AWS Athena.\n",
    "Users can write SQL queries to select packages (or files from within packages)\n",
    "using predicates based on package or object-level metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73600303-002f-4460-b0cc-7176fd6f55e1",
   "metadata": {},
   "source": [
    "## Note: Executing Documentation Code  \n",
    "If you import your AWS credentials for use by `boto3`, you can edit and execute code directly from the notebook version of this document.\n",
    "You can alternatively copy and paste it into your Python editor.\n",
    "<!--pytest.mark.skip-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e7ea237-20bc-470a-b009-047a93d833b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#%env AWS_PROFILE=default\n",
    "%pip install boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5125f6c0-b75d-4230-a81e-63f91073d091",
   "metadata": {},
   "source": [
    "This allows you to configure AWS services by calling Python objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c90a031d-3d71-48a2-95e4-3cbb7923375c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session(region_name='us-east-1')\n"
     ]
    }
   ],
   "source": [
    "import boto3,json,re,time\n",
    "SESSION = boto3.session.Session()\n",
    "print(SESSION)\n",
    "REGION=SESSION.region_name\n",
    "\n",
    "ATHENA = boto3.client('athena')\n",
    "IAM = boto3.resource('iam')\n",
    "S3 = boto3.client('s3')\n",
    "\n",
    "def stat(response): print(response[\"ResponseMetadata\"][\"HTTPStatusCode\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f789d50d-ad7d-474b-8d65-c8e17333db64",
   "metadata": {},
   "source": [
    "## I. Create Athena Configuration: Workgroup, Bucket, and Database\n",
    "\n",
    "Quilt expects a dedicated bucket for the output from Athena queries, which is best to setup in its own workgroup and database.\n",
    "\n",
    "1. Create the output Bucket `<mycompany>-quilt-athena-output`\n",
    "2. Create a `QuiltWorkgroup` that uses that Bucket\n",
    "3. Create an Athena Database `quilt-metadata` for that Workgroup\n",
    "\n",
    "Later we will explicitly grant Quilt access to that Bucket.\n",
    "<!--pytest-codeblocks:cont-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f19f58b6-8415-435a-88c9-af3212fad6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "COMPANY=\"mycompany\"\n",
    "ATHENA_BUCKET=f\"{COMPANY}-quilt-athena-output\"\n",
    "ATHENA_DB=\"quilt_metadata\"\n",
    "ATHENA_URL=\"s3://\"+ATHENA_BUCKET\n",
    "ATHENA_WORKGROUP=\"QuiltQueries\"\n",
    "\n",
    "ARN_PREFIX=\"arn:aws:s3:::\"\n",
    "ARN_ATHENA=ARN_PREFIX+ATHENA_BUCKET\n",
    "\n",
    "# Create bucket in default region\n",
    "\n",
    "bucket = S3.create_bucket(Bucket=ATHENA_BUCKET) if REGION == 'us-east-1'\\\n",
    "else S3.create_bucket(Bucket=ATHENA_BUCKET, CreateBucketConfiguration=location) \n",
    "stat(bucket)\n",
    "#print(bucket)\n",
    "\n",
    "# Create Workgroup which outputs to that Bucket (if needed)\n",
    "\n",
    "lwg = ATHENA.list_work_groups()\n",
    "wgs = [ wg['Name'] for wg in lwg['WorkGroups'] ]\n",
    "\n",
    "if ATHENA_WORKGROUP not in wgs:\n",
    "    cwg = ATHENA.create_work_group(Name=ATHENA_WORKGROUP, Description='Quilt uses this for Athena SQL Queries')\n",
    "    stat(cwg)\n",
    "\n",
    "# Configure Workgroup to use that Bucket\n",
    "uwg = ATHENA.update_work_group(\n",
    "    WorkGroup=ATHENA_WORKGROUP,\n",
    "    ConfigurationUpdates={\n",
    "        'ResultConfigurationUpdates': {\n",
    "            'OutputLocation': ATHENA_URL,\n",
    "        },\n",
    "    },\n",
    ")\n",
    "stat(uwg)\n",
    "\n",
    "# Create new GLUE Database\n",
    "\n",
    "sqe = ATHENA.start_query_execution(\n",
    "    QueryString=f'create database {ATHENA_DB}',\n",
    "    ResultConfiguration={'OutputLocation': ATHENA_URL+'/queries/'})\n",
    "stat(sqe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753c6d28-c415-4d4e-9846-43c0fd6c4057",
   "metadata": {},
   "source": [
    "## II. Granting Access to Athena\n",
    "\n",
    "By default, Quilt runs with very conservative permissions that do not allow access to [Amazon Athena](https://docs.aws.amazon.com/athena/latest/ug/what-is.html). To enable Athena SQL queries by your Quilt users, you must:\n",
    "\n",
    "### A. Create a new Athena policy.\n",
    "\n",
    "The standard [AmazonAthenaFullAccess](https://console.aws.amazon.com/iam/home#/policies/arn:aws:iam::aws:policy/AmazonAthenaFullAccess) policy is more permissive than necessary.  For production usage, we recommend creating a policy limited to only the above Bucket:\n",
    "<!--pytest-codeblocks:cont-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2f2b070-6bfa-4161-aaab-d71ca481dbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy AthenaQuiltAccess already exists\n"
     ]
    }
   ],
   "source": [
    "# https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/iam.html#IAM.ServiceResource.create_policy\n",
    "# https://docs.aws.amazon.com/athena/latest/ug/workgroups-access.html\n",
    "\n",
    "AthenaQuiltAccess={\n",
    "            \"Version\": \"2012-10-17\",\n",
    "            \"Statement\": [\n",
    "                {\n",
    "                    \"Effect\": \"Allow\",\n",
    "                    \"Action\": [\n",
    "                        \"athena:*\"\n",
    "                    ],\n",
    "                    \"Resource\": [\n",
    "                        \"*\"\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"Effect\": \"Allow\",\n",
    "                    \"Action\": [\n",
    "                        \"glue:GetDatabase\",\n",
    "                        \"glue:GetDatabases\",\n",
    "                        \"glue:CreateTable\",\n",
    "                        \"glue:DeleteTable\",\n",
    "                        \"glue:UpdateTable\",\n",
    "                        \"glue:GetTable\",\n",
    "                        \"glue:GetTables\",\n",
    "                    ],\n",
    "                    \"Resource\": [\n",
    "                        \"*\"\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"Effect\": \"Allow\",\n",
    "                    \"Action\": [\n",
    "                        \"s3:GetBucketLocation\",\n",
    "                        \"s3:GetObject\",\n",
    "                        \"s3:ListBucket\",\n",
    "                        \"s3:ListBucketMultipartUploads\",\n",
    "                        \"s3:ListMultipartUploadParts\",\n",
    "                        \"s3:AbortMultipartUpload\",\n",
    "                        \"s3:CreateBucket\",\n",
    "                        \"s3:PutObject\",\n",
    "                        \"s3:PutBucketPublicAccessBlock\"\n",
    "                    ],\n",
    "                    \"Resource\": [\n",
    "                        ARN_ATHENA\n",
    "                    ]\n",
    "                },\n",
    "\n",
    "            ]\n",
    "}\n",
    "try: \n",
    "    AthenaQuiltPolicy = IAM.create_policy(\n",
    "        PolicyName='AthenaQuiltAccess',\n",
    "        PolicyDocument=json.dumps(AthenaQuiltAccess),\n",
    "        Description='Minimal Athena Access policy for Quilt'\n",
    "    )\n",
    "    print(AthenaQuiltPolicy)\n",
    "except:\n",
    "    print(\"Policy AthenaQuiltAccess already exists\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e848b6d-57b3-46dd-9675-63e8ae1c4e7a",
   "metadata": {},
   "source": [
    "### B. Attach this policy to your CloudFormation stack.\n",
    " \n",
    "This needs to be done manually by your AWS Administrator:\n",
    "\n",
    "1. Go to the [CloudFormation console](https://console.aws.amazon.com/cloudformation)\n",
    "2. Select the Quilt stack\n",
    "3. Click \"Update\"\n",
    "4. Add the above ARN to the \"ManagedUserRoleExtraPolicies\" field.\n",
    "5. Save\n",
    "    \n",
    "### C. Add that AWS policy as a Quilt catalog Policy\n",
    "\n",
    "This needs to be done manually by a Quilt Administrator:\n",
    "\n",
    "1. Login to your Quilt instance at, e.g. https://quilt.mycompany.com\n",
    "2. Click on \"Admin Settings\" in the upper right\n",
    "3. Scroll down to the \"Policies\" section on the bottom\n",
    "4. Click on the \"+\" to create a new Policy\n",
    "5. Set Title to \"AthenaQuiltAccess\"\n",
    "6. Check \"Manually set ARN\" and enter ARN of Athena policy.\n",
    "7. Click \"Create\"\n",
    "    \n",
    "### D. Attach that Policy to a (new) Quilt Role\n",
    "\n",
    "You cannot attach a policy to the \"Custom\" Roles, so you will usually need to first create a new Role:\n",
    "\n",
    "1. From \"Admin Settings\", scroll to \"Roles\"\n",
    "2. Click on the \"+\" to create a new Role\n",
    "3. Set Name to e.g., \"AthenaAccessRole\"\n",
    "4. Click on \"No policies attached.  Attach a policyâ€¦\"\n",
    "5. Select the \"AthenaQuiltAccess\" policy from before\n",
    "6. Click \"Create\"\n",
    "\n",
    "See [Users and roles](../Catalog/Admin.md) for more details on access control management in Quilt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6909243d-27b8-4be2-93b4-bda0d26514e5",
   "metadata": {},
   "source": [
    "## III. Defining Per-Bucket Metadata Tables in Athena\n",
    "The next step is enabling Athena to query the package contents and metadata\n",
    "for a specific Quilt bucket, by creating proxy tables and views that represent those files:\n",
    "<!--pytest-codeblocks:cont-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3f532d0-62e3-4aa2-a682-0f4cbeaac663",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUILT_BUCKET=\"quilt-example\"   # Use your own\n",
    "QUILT_URL=\"s3://\"+QUILT_BUCKET # With S3 Prefix\n",
    "\n",
    "BUCKET_ID=QUILT_BUCKET.replace('-','_')\n",
    "MANIFEST_TABLE=f\"{BUCKET_ID}_quilt_manifests\"\n",
    "PACKAGES_TABLE=f\"{BUCKET_ID}_quilt_packages\"\n",
    "PACKAGES_VIEW=f\"{BUCKET_ID}_quilt_packages_view\"\n",
    "OBJECTS_VIEW=f\"{BUCKET_ID}_quilt_objects_view\"\n",
    "DDL = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2179997c-399b-43a8-b280-aed4cf411e8a",
   "metadata": {},
   "source": [
    "### A. Manifests table\n",
    "The following Athena DDL will build a table of all the manifests in that bucket\n",
    "(all package-level and object-level metadata).\n",
    "<!--pytest-codeblocks:cont-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9b4d2fa-6463-465b-8072-db45466ed596",
   "metadata": {},
   "outputs": [],
   "source": [
    "DDL[MANIFEST_TABLE] = f\"\"\"\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS `{ATHENA_DB}.{MANIFEST_TABLE}`(\n",
    "  `logical_key` string,\n",
    "  `physical_keys` array<string>,\n",
    "  `size` string,\n",
    "  `hash` struct<type:string,value:string>,\n",
    "  `meta` string,\n",
    "  `user_meta` string,\n",
    "  `message` string,\n",
    "  `version` string)\n",
    "ROW FORMAT SERDE\n",
    "  'org.openx.data.jsonserde.JsonSerDe'\n",
    "WITH SERDEPROPERTIES (\n",
    "  'ignore.malformed.json'='true')\n",
    "STORED AS INPUTFORMAT\n",
    "  'org.apache.hadoop.mapred.TextInputFormat'\n",
    "OUTPUTFORMAT\n",
    "  'org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat'\n",
    "LOCATION\n",
    "  '{QUILT_URL}/.quilt/packages'\n",
    "TBLPROPERTIES (\n",
    "  'has_encrypted_data'='false',\n",
    "  'transient_lastDdlTime'='1605312102')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73215c0a-50a5-4ca4-b618-e88a995a35fe",
   "metadata": {},
   "source": [
    "### B. Package metadata table\n",
    "Package names and top hashes are not stored in the manifests. Rather they are stored in pointer files in the `.quilt/named_packages` folder.\n",
    "The following DDL creates a table from these pointer files to make package\n",
    "top hashes available in Athena.\n",
    "<!--pytest-codeblocks:cont-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ae3532c-a91e-4168-824a-3a73a941f9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DDL[PACKAGES_TABLE] = f\"\"\"\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS `{ATHENA_DB}.{PACKAGES_TABLE}`(\n",
    "  `hash` string)\n",
    "ROW FORMAT DELIMITED\n",
    "  FIELDS TERMINATED BY ',' STORED AS INPUTFORMAT\n",
    "  'org.apache.hadoop.mapred.TextInputFormat'\n",
    "OUTPUTFORMAT\n",
    "  'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\n",
    "LOCATION\n",
    "  '{QUILT_URL}/.quilt/named_packages'\n",
    "TBLPROPERTIES (\n",
    "  'has_encrypted_data'='false',\n",
    "  'transient_lastDdlTime'='1557626200')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa42355a-6791-4a6c-902e-29b64943abef",
   "metadata": {},
   "source": [
    "### C. View of package-level metadata\n",
    "The DDL below creates a view that contains package-level information including: \n",
    "* User\n",
    "* Package name\n",
    "* Tophash\n",
    "* Timestamp\n",
    "* Commit message\n",
    "<!--pytest-codeblocks:cont-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8d48a9c-62a0-46d0-960a-ba938d81644d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SLASH=r'\\/([^\\/]+)'\n",
    "S1=r'\\/'\n",
    "S3_MATCH=f'^s3:{S1}{SLASH}{SLASH}{SLASH}{SLASH}'\n",
    "DDL[PACKAGES_VIEW] = f\"\"\"\n",
    "CREATE OR REPLACE VIEW {ATHENA_DB}.{PACKAGES_VIEW} AS\n",
    "WITH\n",
    "  npv AS (\n",
    "    SELECT\n",
    "      regexp_extract(\"$path\", '{S3_MATCH}', 4) as user,\n",
    "      regexp_extract(\"$path\", '{S3_MATCH}{SLASH}', 5) as name,\n",
    "      regexp_extract(\"$path\", '[^/]+$') as timestamp,\n",
    "      {PACKAGES_TABLE}.\"hash\"\n",
    "      FROM {PACKAGES_TABLE}\n",
    "  ),\n",
    "  mv AS (\n",
    "    SELECT\n",
    "      regexp_extract(\"$path\", '[^/]+$') as tophash,\n",
    "        manifest.\"meta\",\n",
    "        manifest.\"message\"\n",
    "      FROM\n",
    "        {MANIFEST_TABLE} as manifest\n",
    "      WHERE manifest.\"logical_key\" IS NULL\n",
    "  )\n",
    "SELECT\n",
    "  npv.\"user\",\n",
    "  npv.\"name\",\n",
    "  npv.\"hash\",\n",
    "  npv.\"timestamp\",\n",
    "  mv.\"message\",\n",
    "  mv.\"meta\"\n",
    "FROM npv\n",
    "JOIN\n",
    "  mv\n",
    "ON\n",
    "  npv.\"hash\" = mv.\"tophash\"\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2111bfa0-ccea-4169-aeda-b67b8b317ed9",
   "metadata": {},
   "source": [
    "### D. View of object-Level metadata\n",
    "The DDL below creates a view that contains package contents, including:\n",
    "* logical_key\n",
    "* physical_keys\n",
    "* object hash\n",
    "* object metadata\n",
    "<!--pytest-codeblocks:cont-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04648076-121a-488a-abd3-c8c0345e92a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DDL[OBJECTS_VIEW] = f\"\"\"\n",
    "CREATE OR REPLACE VIEW {ATHENA_DB}.{OBJECTS_VIEW} AS\n",
    "WITH\n",
    "  mv AS (\n",
    "    SELECT\n",
    "      regexp_extract(\"$path\", '[^/]+$') as tophash,\n",
    "      manifest.\"logical_key\",\n",
    "      manifest.\"physical_keys\",\n",
    "      manifest.\"size\",\n",
    "      manifest.\"hash\",\n",
    "      manifest.\"meta\",\n",
    "      manifest.\"user_meta\"\n",
    "    FROM\n",
    "      {MANIFEST_TABLE} as manifest\n",
    "    WHERE manifest.\"logical_key\" IS NOT NULL\n",
    "  )\n",
    "SELECT\n",
    "  npv.\"user\",\n",
    "  npv.\"name\",\n",
    "  npv.\"timestamp\",\n",
    "  mv.\"tophash\",\n",
    "  mv.\"logical_key\",\n",
    "  mv.\"physical_keys\",\n",
    "  mv.\"hash\",\n",
    "  mv.\"meta\",\n",
    "  mv.\"user_meta\"\n",
    "FROM mv\n",
    "JOIN\n",
    "  {PACKAGES_VIEW} as npv\n",
    "ON\n",
    "  npv.\"hash\" = mv.\"tophash\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87935de8-2342-4712-b8da-e60e34d56d87",
   "metadata": {},
   "source": [
    "You can run the following Python code to create the preceding tables and views:\n",
    "<!--pytest-codeblocks:cont-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee63b7a-ebf0-4ab0-9a79-899fc0c2238e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Create Athena Tables and Views for quilt-example:\n",
      "\n",
      " - quilt_example_quilt_manifests: 200\n",
      " - quilt_example_quilt_packages: 200\n",
      " - quilt_example_quilt_packages_view: 200\n",
      " - quilt_example_quilt_objects_view: 200\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nCreate Athena Tables and Views for {QUILT_BUCKET}:\\n\")\n",
    "for key in DDL:\n",
    "    resp = ATHENA.start_query_execution(QueryString=DDL[key])\n",
    "    print(f\" - {key}: \", end =\"\")\n",
    "    stat(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fd2809-f568-4401-8c92-fdb36980b9e6",
   "metadata": {},
   "source": [
    "## Example: Querying package-level metadata\n",
    "\n",
    "Suppose we wish to find all .tiff files produced by algorithm version 1.3\n",
    "with a cell index of 5.\n",
    "<!--pytest-codeblocks:cont-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1326cab2-85a1-4a44-ab02-565262f05b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATHENA_TEST = f\"\"\"\n",
    "SELECT * FROM {ATHENA_DB}.{OBJECTS_VIEW}\n",
    "WHERE substr(logical_key, -5)='.tiff'\n",
    "-- extract and query package-level metadata\n",
    "AND json_extract_scalar(meta, '$.user_meta.nucmembsegmentationalgorithmversion') LIKE '1.3%'\n",
    "AND json_array_contains(json_extract(meta, '$.user_meta.cellindex'), '5');\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd20f63-9bce-4aa1-994f-3814ccc21106",
   "metadata": {},
   "source": [
    "You can enter that Query directly in the Athena Query Editor using the QuiltWorkgroup, from the Queries -> Athena SQL tab, or using the following Python code:\n",
    "<!--pytest-codeblocks:cont-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce9308b-676f-48e4-b75b-122adb452be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Athena Query:\n",
      "WorkGroup QuiltQueries\n",
      "\tathena_await[9]=QUEUED\n",
      "\tathena_await[8]=RUNNING\n",
      "\tathena_await[7]=RUNNING\n",
      "\tathena_await[6]=RUNNING\n",
      "\tathena_await[5]=RUNNING\n",
      "athena_await.s3_path: s3://mycompany-quilt-athena-output/21de87e8-88cc-4b6b-ace6-7d213f9a707c.csv\n",
      "athena_await 21de87e8-88cc-4b6b-ace6-7d213f9a707c.csv\n",
      "results\n",
      "(['user', 'name', 'timestamp', 'tophash', 'logical_key', 'physical_keys', 'hash', 'meta', 'user_meta'], [])\n"
     ]
    }
   ],
   "source": [
    "# https://www.ilkkapeltola.fi/2018/04/simple-way-to-query-amazon-athena-in.html\n",
    "QUERY_ID='QueryExecutionId'\n",
    "TAIL_PATH=re.compile(r'.*\\/(.*)')\n",
    "\n",
    "def athena_await(resp, max_execution = 10):\n",
    "    id = resp[QUERY_ID]\n",
    "    state = 'RUNNING'\n",
    "    while (max_execution > 0 and state in ['RUNNING', 'QUEUED']):\n",
    "        max_execution = max_execution - 1\n",
    "        response = ATHENA.get_query_execution(QueryExecutionId = id)\n",
    "        if 'QueryExecution' in response and \\\n",
    "                'Status' in response['QueryExecution'] and \\\n",
    "                'State' in response['QueryExecution']['Status']:\n",
    "            state = response['QueryExecution']['Status']['State']\n",
    "            if state == 'FAILED':\n",
    "                return False\n",
    "            elif state == 'SUCCEEDED':\n",
    "                s3_path = response['QueryExecution']['ResultConfiguration']['OutputLocation']\n",
    "                print('athena_await.s3_path:', s3_path)\n",
    "                filename = TAIL_PATH.findall(s3_path)[0]\n",
    "                return filename\n",
    "        print(f\"\\tathena_await[{max_execution}]={state}\")\n",
    "        time.sleep(1)\n",
    "\n",
    "    return False\n",
    "\n",
    "def athena_results(resp):\n",
    "    id = resp[QUERY_ID]\n",
    "    raw = ATHENA.get_query_results(QueryExecutionId=id)\n",
    "    if raw.get('ResponseMetadata', {}).get('HTTPStatusCode') == 200 and 'Rows' in raw.get('ResultSet', {}):\n",
    "        data = [x['Data']for x in raw['ResultSet']['Rows']]\n",
    "        cols = [d.get('VarCharValue') for d in data[0]]\n",
    "        rows = [[d.get('VarCharValue') for d in row] for row in data[1:]]\n",
    "        return (cols, rows)\n",
    "    else:\n",
    "        return \"Query in progress...\"\n",
    "\n",
    "print(\"\\nTest Athena Query:\")\n",
    "print('WorkGroup', ATHENA_WORKGROUP)\n",
    "resp = ATHENA.start_query_execution(\n",
    "    WorkGroup=ATHENA_WORKGROUP,\n",
    "    QueryString=ATHENA_TEST,\n",
    "    ResultConfiguration={'OutputLocation': ATHENA_URL}\n",
    ")\n",
    "print('athena_await', athena_await(resp))\n",
    "results = athena_results(resp)\n",
    "print('results')\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
